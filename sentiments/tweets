#!/usr/bin/env python3

import os
import sys
import nltk
import html

from analyzer import Analyzer
from termcolor import colored
from helpers import get_user_timeline

from twython import Twython
from twython import TwythonAuthError, TwythonError, TwythonRateLimitError

def main():

    # ensure proper usage
    if len(sys.argv) != 2:
        sys.exit("Usage: ./smile word")

    # absolute paths to lists
    positives = os.path.join(sys.path[0], "positive-words.txt")
    negatives = os.path.join(sys.path[0], "negative-words.txt")
    
    # getting the user's 50 recent tweets
    tweets = get_user_timeline(sys.argv[1], 50)
    
    # error message if username is invalid or a private account
    if tweets == None:
        sys.exit("Username entered doesn't exist or is a private account")

    # instantiate analyzer
    analyzer = Analyzer(positives, negatives)
    
    # Importing the Tokenizer and using it
    tokenizer = nltk.tokenize.TweetTokenizer()
        
    # analyze tweet
    for tweet in tweets:
        counter = 0
        
        # tokens contains the whole tweet split into words
        tokens = tokenizer.tokenize(tweet)
        
        # Iterating through all the words in the whole tweet
        for token in tokens:
            
            # analyze word
            score = analyzer.analyze(token)
            counter += score
        
        if counter > 0.0:
            print(colored(" {} {}".format(counter, tweet), "green"))
        elif counter < 0.0:
            print(colored("{} {}".format(counter, tweet), "red",))
        else:
            print(colored(" {} {}".format(counter, tweet), "yellow"))

if __name__ == "__main__":
    main()